# Your First Modell - Fashion MNIST

## Interview with Sebastian

" What frontiers and challenges do you think are going to be the most impactful for deep learning in the next 10 years? "
> I Would say two things.
> One is a more general intelligence training in network to do more than one task. 
> People can do more than one task and never should do the same thing.
>
> The second is bring it to market. 
> The great vision of machine learning is that it allows computer to observe, expose with them their work, 
> and they pick up the patterns and help other people to be as good as the best experts.
> So it could be done in law, medicine, driving cars.

" What applications are you most excited about seeing machine learning applied to ? "

> A lot, a lot. Medical is very high on the list.
> I think there are a lot of diseases if they could detect them early, like cancer, they could have much better treatment.
> The same is true for Alzheimer, and for congestive heart failure, where there's actually ideas to bring instrument to the house in some smart way, using machine learning, deep learning to detect these things before even people will detect them.
>
> I'd say anything repetitive, anything office work where you do the same stuff over again, like accountants, for example, lawyers .

" Can you tell us a little bit more about what you think of dense layers? "

> Well, so every network can be connected differnetly. Some of them have a very sparse connectivity which gives you better scalability so you can beat larger nerworks.
> Sometimes you don't quite know the Internet things from the beginning, so you connect everything with everything. 
> That's called dense layer, and it's actually a much more potent learning machine than something that's more structured.


## Introduction

### Regression predicts a numeric value

We will create a neural network that can recognize items of clothing and images.

## Fashion MNIST Dataset

* consist of 28 by 28 pixel gray-scale images of clothing
* contains images of t-shrits and tops, sandals, and even ankle boots

| label | Class |
|-------|-------|
|0|T-shirt/top|
|1|Trouser|
|2|Pullover|
|3|Dress|
|4|Coat|
|5|Sandals|
|6|Shirt|
|7|Sneaker|
|8|Bag|
|9|Ankle boot|

* the Fashion-MNIST dataset contains 70,000 images

We will use 60,000 to train the neural network. Then, we will use the remaing 10,000 images to test how well our neural network can recognize the items of clothing.



## Neural Network

#### Input image (28x28 = 784 pixels) 
28x28 converted into a one dimensional array to 784 units

This process of converting a 2D image into a vector is called flattening and code, this is performed through a flattened layer.

    tf.keras.layers.Flatten(input_shape=(28,28,1))

### Dense layer (128 units)
The input will be fully connected to the first dense layer of our network, where we've chosen to use 128 units.

    tf.keras.layers.Dense(128,activation=tf.nn.relu)

### Output (10 units)
Finally, the last layer also known as the output layer, contains 10 units.
This is because, our fashion MNIST dataset contains 10 types of articles of clothing.
Each of these 10 output values will specify the probability that the image of that specific types of clothing.
Since thess 10 output values refer to probabilities if you sum them up the result will be 1. 
Now we need the output layer to create these probability values for each of our classes .

    tf.keras.layers.Dense(10,activation=tf.nn.softmax)
### The Rectified Linear Unit (ReLU)
In this lesson we talked about ReLU and how it gives our Dense layer more power. ReLU stands for Rectified Linear Unit and it is a mathematical function 

ReLU function gives an output of 0 if the input is negative or zero, and if input is positive, then the output will be equal to the input.

ReLU gives the network the ability to solve nonlinear problems.

Converting Celsius to Fahrenheit is a linear problem because f = 1.8*c + 32 is the same form as the equation for a line, y = m*x + b. But most problems we want to solve are nonlinear. In these cases, adding ReLU to our Dense layers can help solve the problem.

ReLU is a type of activation function. There several of these functions (ReLU, Sigmoid, tanh, ELU), but ReLU is used most commonly and serves as a good default. To build and use models that include ReLU, you don’t have to understand its internals. But, if you want to know more, see this article on ReLU in Deep Learning(https://www.kaggle.com/dansbecker/rectified-linear-units-relu-in-deep-learning).

Let’s review some of the new terms that were introduced in this lesson:

* Flattening: The process of converting a 2d image into 1d vector
* ReLU: An activation function that allows a model to solve nonlinear problems
* Softmax: A function that provides probabilities for each possible output class
* Classification: A machine learning model used for distinguishing among two or more output categories


## Training and Testing

When training a Machine Learning model, you always need to split your data set into at least two diffent partitions, the data you use for training, and the data you use for testing.


TensorFlow Datasets provides a collection of datasets ready to use with TensorFlow. (https://medium.com/tensorflow/introducing-tensorflow-datasets-c7f01f7e19f3)

Datasets are typically split into different subsets to be used at various stages of training and evaluation of the neural network. In this section we talked about:

Training Set: The data used for training the neural network.
Test set: The data used for testing the final performance of our neural network.
The test dataset was used to try the network on data it has never seen before. This enables us to see how the model generalizes beyond what it has seen during training, and that it has not simply memorized the training examples.

In the same way, it is common to use what is called a Validation dataset. This dataset is not used for training. Instead, it it used to test the model during training. This is done after some set number of training steps, and gives us an indication of how the training is progressing. For example, if the loss is being reduced during training, but accuracy deteriorates on the validation set, that is an indication that the model is memorizing the test set.

The validation set is used again when training is complete to measure the final accuracy of the model.

You can read more about all this in the Training and Test Sets lesson of Google’s Machine Learning Crash Course. (https://developers.google.com/machine-learning/crash-course/training-and-test-sets/video-lecture) 


## Colab: Fashion MNIST

### Colab Notebook
To access the Colab Notebook, login to your Google account and click on the link below:

Fashion MNIST  (https://colab.research.google.com/github/tensorflow/examples/blob/master/courses/udacity_intro_to_tensorflow_for_deep_learning/l03c01_classifying_images_of_clothing.ipynb)



















