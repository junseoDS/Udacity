# Deep Learning with PyTorch

## Welcome !

Welcome! In this lesson, you'll learn how to use PyTorch for building deep learning models. PyTorch was released in early 2017 and has been making a pretty big impact in the deep learning community. It's developed as an open source project by the [Facebook AI Research team](https://research.fb.com/category/facebook-ai-research/), but is being adopted by teams everywhere in industry and academia. In my experience, it's the best framework for learning deep learning and just a delight to work with in general. By the end of this lesson, you'll have trained your own deep learning model that can classify images of cats and dogs.

I'll first give you a basic introduction to PyTorch, where we'll cover tensors - the main data structure of PyTorch. I'll show you how to create tensors, how to do simple operations, and how tensors interact with NumPy.

Then you'll learn about a module called autograd that PyTorch uses to calculate gradients for training neural networks. Autograd, in my opinion, is amazing. It does all the work of backpropagation for you by calculating the gradients at each operation in the network which you can then use to update the network weights.

Next you'll use PyTorch to build a network and run data forward through it. After that, you'll define a loss and an optimization method to train the neural network on a dataset of handwritten digits. You'll also learn how to test that your network is able to generalize through validation.

However, you'll find that your network doesn't work too well with more complex images. You'll learn how to use pre-trained networks to improve the performance of your classifier, a technique known as transfer learning.

Follow along with the videos and work through the exercises in your own notebooks. If you get stuck, check out my solution videos and notebooks.


### Get the notebooks

The notebooks for this lesson will be provided in the classroom, but if you wish to follow along on your local machine, then the instructions below will help you get setup and ready to learn!

All the notebooks for this lesson are available from [our deep learning repo on GitHub](https://github.com/udacity/deep-learning-v2-pytorch). Please clone the repo by typing

git clone https://github.com/udacity/deep-learning-v2-pytorch.git

in your terminal. Then navigate to the intro-to-pytorch directory in the repo.

Follow along in your notebooks to complete the exercises. I'll also be providing solutions to the exercises, both in videos and in the notebooks marked (Solution).


### Dependencies
These notebooks require PyTorch v0.4 or newer, and torchvision. The easiest way to install PyTorch and torchvision locally is by following [the instructions on the PyTorch site](https://pytorch.org/get-started/locally/). Choose the stable version, your appropriate OS and Python versions, and how you'd like to install it. You'll also need to install numpy and jupyter notebooks, the newest versions of these should work fine. Using the conda package manager is generally best for this,

conda install numpy jupyter notebook

If you haven't used conda before, [please read the documentation](https://conda.io/en/latest/) to learn how to create environments and install packages. I suggest installing Miniconda instead of the whole Anaconda distribution. The normal package manager pip also works well. If you have a preference, go with that.

The final part of the series has a soft requirement of a GPU used to accelerate network computations. Even if you don't have a GPU available, you'll still be able to run the code and finish the exercises. PyTorch uses a library called [CUDA](https://developer.nvidia.com/cuda-zone) to accelerate operations using the GPU. If you have a GPU that CUDA supports, you'll be able to install all the necessary libraries by installing PyTorch with conda. If you can't use a local GPU, you can use cloud platforms such as [AWS](https://docs.aws.amazon.com/dlami/latest/devguide/gpu.html), [GCP](https://cloud.google.com/gpu/), and [FloydHub](https://www.floydhub.com/) to train your networks on a GPU.

Our Nanodegree programs also provide GPU workspaces in the classroom, as well as credits for AWS.


### Feedback

If you have problems with the notebooks, please contact support or create an issue on the repo. We're also happy to incorporate your improvements through pull requests.



## Pre-Notebook


### Notebooks : Intro to PyTorch

Time to get started building networks with PyTorch! We've prepared a set of eight notebooks that lead you through building deep neural networks in PyTorch. Work your way through the notebooks completing the exercises as best as you can. Feel free to check out our solutions both in the videos and in the solution notebooks, but remember that it's super important that you type in the correct code yourself. If you want to learn how to do this, you have to write in the code yourself, understand what every line of the code is doing, and get everything to work properly yourself. Please use our solutions only to guide your learning.

It's suggested that you open these notebooks in a new, working tab and continue working on it as you go through the instructional videos in this tab. This way you can toggle between learning new skills and coding/applying new skills.

To open the notebooks, you have two options:

> * Go to the next page in the classroom (recommended).
> 
> * Clone the repo from [Github](https://github.com/udacity/deep-learning-v2-pytorch) and open the Jupyter notebooks in the intro-to-pytorch folder. You can either download the repository with git clone https://github.com/udacity/deep-learning-v2-pytorch.git, or download it as an archive file from [this link](https://codeload.github.com/udacity/deep-learning-v2-pytorch/zip/master).






### GPU Workspaces

Part 8 here shows you how to accelerate network computations using a GPU. So, the next workspace is GPU-enabled, which means you can select to train on a GPU instance. Since you are limited on the GPU hours you have, the recommendation is this:

* Work in CPU mode while developing your models and such.
* Make sure the network is learning (the training loss is dropping) using just the CPU.
* When you're ready to train for real and optimize the hyperparameters, enable the GPU










## Tips, Tricks and Other Notes

### Watch those shapes

In general, you'll want to check that the tensors going through your model and other code are the correct shapes. Make use of the .shape method during debugging and development.

### A few things to check if your network isn't training appropriately

Make sure you're clearing the gradients in the training loop with optimizer.zero_grad(). If you're doing a validation loop, be sure to set the network to evaluation mode with model.eval(), then back to training mode with model.train().

### CUDA errors

Sometimes you'll see this error:

    RuntimeError: Expected object of type torch.FloatTensor but found type torch.cuda.FloatTensor for argument #1 ‘mat1’

You'll notice the second type is torch.cuda.FloatTensor, this means it's a tensor that has been moved to the GPU. It's expecting a tensor with type torch.FloatTensor, no .cuda there, which means the tensor should be on the CPU. PyTorch can only perform operations on tensors that are on the same device, so either both CPU or both GPU. If you're trying to run your network on the GPU, check to make sure you've moved the model and all necessary tensors to the GPU with .to(device) where device is either "cuda" or "cpu".
