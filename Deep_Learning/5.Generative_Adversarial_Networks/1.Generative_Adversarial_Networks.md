# Generative Adversarial Networks



## Introducing Ian Goodfellow

Ian is the inventor of Gerative Adversarial Networks, a major advancement in deep learning. 

* TA at Stanford
* Textbook co-authour
* Steering committee of Distill

### GANs

There are machine learning model that can imagine new things. 

If you give them a training set of somthing like images, they can make entirely new images that are realistic, even though they've never been seen before. 




## Applications of GANs

GANs are used for generating realistic data. Most of the application of GANs so far have been for images. 

For example, the __StackGAN model__ is really great at taking a textual description of a bird than generating a high resolution photo of a bird matching that description.  The GAN is drawing a sample from the probability distribution over all hyperthetical images matching that description, so you can keep running the GAN to get more images. 

A tool called __iGAN__ developed in collaboration between Berkeley and Adobe uses GANs to help artists. As the user draws very crude sketches using the mouse, iGAN searches for the nearest possible realistic image. 

GANs can also be used for image to image translation where images in one domain can be turned into images in another domain. Blueprints for building can be turned  into photos of finished buildings, or drawing of cats can be turned into realistic photos of cats. 

What's even more exciting is that image-to-image translation models can be trained in an unsupervised way. Facebook AI researchers showed how to train a model that can turn a photo of a face into a cartoon of a face. The model was trained on photos and on cartoons, but it did not need pairs of images showing which phto corresponds to which cartoon. 

Researchers from Nvidia showed how to use a similar GAN technique. For example, to turn photos of day scenes into photos of night scenes. At Berkeley, a model called CycleGAN is especially good at unsupervised image-to-image translation. 

GANs can also be used to create realistic simulated training sets or enviroments to train other machine learning models or reinforcement learning agents. 
Apple's first AI researcher paper was about using GANs to take 3D rendered images of eyes and change them to appear more realistic. 


GANs can also be used for imitation learning. We can think of the actions taken by a reinforcement learning agent as being a kind of data just as GANs can learn to imitate data like the images in training set of several photos, GANs can learn to imitate the action taken by a human expert. 


### Links to Resources

* [StackGAN](https://arxiv.org/abs/1612.03242) realistic image synthesis
* [iGAN](https://github.com/junyanz/iGAN) interactive image generation
* CartoonGAN, linked below

You'll learn much more about Pix2Pix and CycleGAN formulations, later in this program!





## How GANs work


Generative adversarial networks are a kind of generative model. 

Recurrent text models generate assignats one word ata time. It's also possible to make one word at a time, style model per images, where the model generates the image one pixel at a time. In general, this strategy is called, __'fully visible belief networks' going back to the '90s or auto regressive models__ as these models were renamed when they were rediscovered later. 

But, what if we would like to generate an entire output value such as entire image in one shot? GANs are kind of generative model that let's us generate a whole image in parallel. GANs use a differentiable function represented by a neural networks as a generator network. The generator network takes random noise as input, then runs that noise through a differentialbe function to transorm the noise and reshape it to have recognizable structure. The output of the generative network is a realistic image. The choice of the random input noise determines which image will come out of the generator network. Running the generator network with many diffrent input noise values produces many different realistic output images. The goal is for these images to be fair samples from the distribution over real data. Of course, the generator net doesn't start out producing realistic images. It has to be trained. The training process for a generative model is very different from the training process for a supervised learning model. __For a supervised learning model__, we show the model an image of a traffic light and we tell it, this is traffic light. __For generative model__ there's no output to associate with each image. We just show the model a lot of images and ask it to make more images that come from the same probability distribution.

But how do we actually get the model to do that? 
Most generative models are trained by adjusting the parameters to maximize the probability that the generator net will generate the training data set. 
Unfortunately for a lot of interesting models, it can be very difficult to compute this probability. Most generative models get around that with some kind of approximation. 

GANs use ab approximation where a second networks, called __the discriminator__, learns to guide the generator. The discriminator is just a regular neural net classifier, like you have all seen several times by now. During the training process, the discriminator shown real images from the training data half the time and fake images from the generator the other half of the time. The discriminator is trained to output the probability that the input is real. So it tries to assign a probability near 1 to real images, and a probability near zero to fake images. Meanwhile the generator tries to do the opposite. 
Over time, the generator is forced to produce more realistic output to fool the discriminator. 




You can find more information on the graph in the video in Figure 1 of https://arxiv.org/pdf/1406.2661.pdf.



## Games and Equilibria

The word adversarial in generative networks means that the two networks, the generator and the discriminator, are in a competition with each other.

Game theory is a branch of applied math that was founded by John Von Neumann and later signficantly extended by John Nash. Game theory can be used to model cooperation and conflict between rational agents in any situation, where each agent can choose from som set of actions, and the choice of action determines a well-defined payoff for each player. 

What happens if we adapt each player's strategy over the course of several games? 
If the players are allowed to randomize their moves, they will eventually reach __an equilibrium where each player chooses their actions uniformly at random.__ An equilibrium is an importatnt situation in game theory where neither player can improve their payoff by changing their own strategy, assuming the other player's strategy stays the same. To understand GANs, we need to think about how payoffs and equilibria work in the context of machine learning. If we can identify an equilibrium in the GAN game, we can use that equilibrium as a defining charateristic to understand that game. Most machine learning models we have seen so far are based on optimization.   


## Tips for Training GANs

Leaky ReLUs help to make sure that the gradient can flow through the entire architecture. It's important for GANs because the only way that generator can learn is to receive a gradient from the discriminator. A popular choice for the output of the generator is the tanh activation function. This means that your data should be scaled to the interval ranging from -1 to +1.  
Finally, for most version of GANs, the output of the discriminator needs to be probability. To enforce that constraint, we use sigmoid unit as the output.

GANs are different from many other machine learning models because they require running two optimization algorithms simulaneously:

* Discriminator loss
* Generator loss

We use one optimizier to minimize the loss for the discriminator, while simultaneously use another optimizer to minimize the loss for the generator. Adam is a good choice for the optimizer.

To set up the discriminator loss, recall that we want to train the discriminator to output values near one for real data and near zero fo fake data. 

Use the numerically stable version of cross-entropy where the loss is computed the logits.
The logits are the values produced by the discriminator right before the sigmoid. If you use the probability values that come out of the sigmoid, there can be problems with rounding error when the sigmoid is near 0 or 1.
One GAN-specific trick is to multiply 0 or 1 labels by a number that is just a little bit smaller than 1, so that you replace labels of one with labels of, 0.9, and keep the 0 labels at 0. This is GAN-specific version of the label smoothing strategy used to regularize normal classifiers. It helps the discriminator to generalize better and avoid learning to make extreme predictions when extrapolaing. 

For the generator loss, you wan to set up another cross- entropy loss, but with the labels flipped. In other words, the generator will maximizer the log probability of the wrong labels. A log of people like to use negative d-loss as the expression for g-loss. 



### Improved Training Techniques for GANs
[Read the paper](https://s3.amazonaws.com/video.udacity-data.com/topher/2018/November/5bea0c6a_improved-training-techniques/improved-training-techniques.pdf), that describes improved training techniques for GANs!



## Generating Fake Images


## GAN examples

If you'd like to read about even more applications of GANs, I recommend this [Medium article](https://medium.com/@jonathan_hui/gan-some-cool-applications-of-gans-4c9ecca35900) which does an overview of interesting applications!

The tulip generation model was created by the artist Anna Ridler, and you can read about her data collection method and inspiration in [this article](https://www.fastcompany.com/90237233/this-ai-dreams-in-tulips). Also, check out [the full-length video](https://vimeo.com/287645190)!




## MNIST GAN

We can create a classifier by training a lot of MNSIT images. As the classifier trains, if it sees an image of a two and it outputs  the label eight, it will identify this as a mistake and change what it's doing, training until becomes more accurate. In this process, the classifier will form some representat=ion different digits. It learns what features distinguish the different kinds of images. 
But you cannot ask classifier to draw a new picture of eight.

To generate new data, you want something that can learn the underlying structure of the training data, like what colors and shapes make up an image of an eight, and use that information to create something entirely new. Adversarial training gives us a way to do this. The idea is that you have two neural networks, a generator, and discriminator. The discriminator is a simple classifier that tries to classify images as eigher real from the training set, or fake generated images. The generator is acting as an adversary to the discriminator. It aims to trick the discriminator, giving it generated images that look as if they've come from the training set. If the generator produces an image that the discriminator thinks is fake, then it will change its behavior and try again. The generator will train until it can fool the discriminator into thinking that its generated data comes from the real training set. So, its goal is to force the discriminator to have as high an error rate as possible. But at the same time, the discriminator is also training. It's alternating between looking at example of real and fake imaes, and getting better at recognizing differences between them. Its goal is to have as low an error rate as possible. So our task will be to define generator and discriminator network with opposing goals. We'll formalize this idea by defining opposing generator and discriminator loss functions. By end of training, the discriminator should not be able to tell the difference between real and fake images, and we'll be able to use our trained generator to create new images of handwritten digits.



### The universal approximation function
The universal approximation theorem states that a feed-forward network with a single hidden layer is able to approximate certain continuous functions. A few assumptions are made about the functions operating on a subset of real numbers and about the activation function applied to the output of this single layer. But this is very exciting! This theorem is saying that a simple, one-layer neural network can represent a wide variety of interesting functions. You can learn more about the theorem [here](https://en.wikipedia.org/wiki/Universal_approximation_theorem).


### Binary Cross Entropy Loss
We've mostly used plain cross entrpy loss in this program, which is a negative log loss applied to the output of a softmax layer.

You can read the [PyTorch documentation, here](https://pytorch.org/docs/stable/nn.html#bceloss).



## eval

Note that the Generator should be set to eval mode for sample generation. It doesn't make too big a difference in this case, but this is to account for the different behavior that a dropout layer has during training vs during model evaluation.

So, in the workspace and Github repository code, we've added the correct evaluation code for generating samples, writing the line G.eval() before we generate samples. We strive to always keep the code that you'll be working with correct and up-to-date!










